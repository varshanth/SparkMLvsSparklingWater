{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_susy_into_df import susy_csv_to_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_csv = '/home/varsrao/Downloads/SUSY.csv'\n",
    "chunksize = 100000\n",
    "num_train_chunks = 5\n",
    "num_test_chunks = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Loading Dataset----\n"
     ]
    }
   ],
   "source": [
    "print('----Loading Dataset----')\n",
    "ds_train_pd_df, ds_test_pd_df, target_col_name, target_col_idx, feature_col_names = susy_csv_to_df(\n",
    "        path_to_csv, chunksize, num_train_chunks, num_test_chunks)\n",
    "col_names = [target_col_name]+feature_col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Creating Spark Context----\n"
     ]
    }
   ],
   "source": [
    "print('----Creating Spark Context----')\n",
    "sqlCtx = SQLContext(sc)\n",
    "ds_spark_df = sqlCtx.createDataFrame(ds_train_pd_df, schema=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Assembling Data----\n"
     ]
    }
   ],
   "source": [
    "print('----Assembling Data----')\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "vecassembler = VectorAssembler(\n",
    "        inputCols=ds_spark_df.columns[:target_col_idx]+ds_spark_df.columns[target_col_idx+1:],\n",
    "        outputCol=\"features\")\n",
    "features_vec = vecassembler.transform(ds_spark_df)\n",
    "features_vec = features_vec.withColumnRenamed(target_col_name, \"label\")\n",
    "features_data = features_vec.select(\"label\", \"features\")\n",
    "feat_train, feat_test = features_data.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Training Model----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set areaUnderROC: 0.8587467199154661\n",
      "Training Accuracy0.7896062110932364\n"
     ]
    }
   ],
   "source": [
    "print('----Training Model----')\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "lrm = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=100).fit(feat_train)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "trainingSummary = lrm.summary\n",
    "roc = trainingSummary.roc.toPandas()\n",
    "plt.plot(roc['FPR'],roc['TPR'])\n",
    "plt.ylabel('False Positive Rate')\n",
    "plt.xlabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()\n",
    "print('Training set areaUnderROC: ' + str(trainingSummary.areaUnderROC))\n",
    "print('Training Accuracy' + str(trainingSummary.accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Testing Model----\n",
      "Test Area Under ROC 0.8585428263533798\n",
      "----End----\n"
     ]
    }
   ],
   "source": [
    "print('----Testing Model----')\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "predictions = lrm.transform(feat_test)\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "print('Test Area Under ROC', evaluator.evaluate(predictions))\n",
    "\n",
    "print('----End----')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
