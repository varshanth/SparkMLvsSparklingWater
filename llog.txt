2019-03-18 17:38:45 WARN  Utils:66 - Your hostname, vblade99 resolves to a loopback address: 127.0.1.1; using 192.168.2.228 instead (on interface wlp3s0)
2019-03-18 17:38:45 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2019-03-18 17:38:46 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
EXPERIMENT 2019-03-18 17:38:46: ----Pyspark Execution----
EXPERIMENT 2019-03-18 17:38:46: ----Dataset: susy Model:logistic_regression----
EXPERIMENT 2019-03-18 17:38:46: ----Chunksize: 100000 Train Chunks:4 Test Chunks: 3----
EXPERIMENT 2019-03-18 17:38:46: ----Loading Dataset----
EXPERIMENT 2019-03-18 17:38:50: ----Creating Spark Context----
2019-03-18 17:38:50 INFO  SparkContext:54 - Running Spark version 2.4.0
2019-03-18 17:38:50 INFO  SparkContext:54 - Submitted application: PySpark_susy_logistic_regression
2019-03-18 17:38:50 INFO  SecurityManager:54 - Changing view acls to: varsrao
2019-03-18 17:38:50 INFO  SecurityManager:54 - Changing modify acls to: varsrao
2019-03-18 17:38:50 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-03-18 17:38:50 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-03-18 17:38:50 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(varsrao); groups with view permissions: Set(); users  with modify permissions: Set(varsrao); groups with modify permissions: Set()
2019-03-18 17:38:51 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 41279.
2019-03-18 17:38:51 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-03-18 17:38:51 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-03-18 17:38:51 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-03-18 17:38:51 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-03-18 17:38:51 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-5adcb985-1ee9-4d77-8ad1-6c271a0db719
2019-03-18 17:38:51 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2019-03-18 17:38:51 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-03-18 17:38:51 INFO  log:192 - Logging initialized @5949ms
2019-03-18 17:38:51 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-03-18 17:38:51 INFO  Server:419 - Started @6035ms
2019-03-18 17:38:51 INFO  AbstractConnector:278 - Started ServerConnector@70b069a8{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-18 17:38:51 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-03-18 17:38:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@70606f76{/jobs,null,AVAILABLE,@Spark}
2019-03-18 17:38:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@64ec279c{/jobs/json,null,AVAILABLE,@Spark}
2019-03-18 17:38:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@52af0cc5{/jobs/job,null,AVAILABLE,@Spark}
2019-03-18 17:38:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1218506c{/jobs/job/json,null,AVAILABLE,@Spark}
2019-03-18 17:38:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@174d4574{/stages,null,AVAILABLE,@Spark}
2019-03-18 17:38:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3d2eba7c{/stages/json,null,AVAILABLE,@Spark}
2019-03-18 17:38:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2cf4201e{/stages/stage,null,AVAILABLE,@Spark}
2019-03-18 17:38:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4991a5d8{/stages/stage/json,null,AVAILABLE,@Spark}
2019-03-18 17:38:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@44689824{/stages/pool,null,AVAILABLE,@Spark}
2019-03-18 17:38:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@44a1b70b{/stages/pool/json,null,AVAILABLE,@Spark}
2019-03-18 17:38:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65b2cf87{/storage,null,AVAILABLE,@Spark}
2019-03-18 17:38:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2149098c{/storage/json,null,AVAILABLE,@Spark}
2019-03-18 17:38:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@21600c39{/storage/rdd,null,AVAILABLE,@Spark}
2019-03-18 17:38:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6830fef1{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-03-18 17:38:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1b8dca87{/environment,null,AVAILABLE,@Spark}
2019-03-18 17:38:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7261a513{/environment/json,null,AVAILABLE,@Spark}
2019-03-18 17:38:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@53417ea2{/executors,null,AVAILABLE,@Spark}
2019-03-18 17:38:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3c69d54d{/executors/json,null,AVAILABLE,@Spark}
2019-03-18 17:38:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@49c5f9b5{/executors/threadDump,null,AVAILABLE,@Spark}
2019-03-18 17:38:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@367384a3{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-03-18 17:38:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e1f48a1{/static,null,AVAILABLE,@Spark}
2019-03-18 17:38:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@cbb0c{/,null,AVAILABLE,@Spark}
2019-03-18 17:38:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7894038e{/api,null,AVAILABLE,@Spark}
2019-03-18 17:38:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@af9b9a5{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-03-18 17:38:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5fc6d544{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-03-18 17:38:51 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.2.228:4040
2019-03-18 17:38:51 INFO  Executor:54 - Starting executor ID driver on host localhost
2019-03-18 17:38:51 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42167.
2019-03-18 17:38:51 INFO  NettyBlockTransferService:54 - Server created on 192.168.2.228:42167
2019-03-18 17:38:51 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-03-18 17:38:51 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.2.228, 42167, None)
2019-03-18 17:38:51 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.2.228:42167 with 366.3 MB RAM, BlockManagerId(driver, 192.168.2.228, 42167, None)
2019-03-18 17:38:51 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.2.228, 42167, None)
2019-03-18 17:38:51 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.2.228, 42167, None)
2019-03-18 17:38:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3cc2d6b{/metrics/json,null,AVAILABLE,@Spark}
EXPERIMENT 2019-03-18 17:38:51: ----Creating Spark DataFrame----
EXPERIMENT 2019-03-18 17:38:56: ----Assembling Data----
EXPERIMENT 2019-03-18 17:38:56: ----Training Model----
EXPERIMENT 2019-03-18 17:40:05: Training Accuracy 0.7891694204229069
EXPERIMENT 2019-03-18 17:40:05: ----Testing Model----
EXPERIMENT 2019-03-18 17:40:19: Test Set Accuracy: 0.7888310468520499
EXPERIMENT 2019-03-18 17:40:19: ----End----
